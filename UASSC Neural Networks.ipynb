{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Machine Learning Project \n",
    "### Neural Network Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose: The goal of this notebook is to serve as a execution of chosen neural network algorithms to train and test the performance of the model with the appropriate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "\n",
    "from neural_classifier import neural_classifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Combined Dataset\n",
    "\n",
    "__Purpose:__ To evaluate the hypothesis of the \"science of cities\", a dataset has been created that combines the London and Paris datasets and then randomizes the training/testing over numerous different intervals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data1 (SOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Validation Data 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading training data1\n",
    "dftrain_data1 = pd.read_csv('Data1/Data1_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading validation data1\n",
    "dfvalid_data1 = pd.read_csv('Data1/Data1_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Concatenating the 2 sets to form ONE TRAINING SET\n",
    "dftrainCombined1 = pd.concat([dftrain_data1, dfvalid_data1], axis=0)\n",
    "\n",
    "# Subsetting training to take the first 10 features only\n",
    "dftrain10feat1 = dftrainCombined1.iloc[:,:10].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>mean5</th>\n",
       "      <th>mean6</th>\n",
       "      <th>mean7</th>\n",
       "      <th>mean8</th>\n",
       "      <th>mean9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_diff11</th>\n",
       "      <th>var_diff12</th>\n",
       "      <th>var_diff13</th>\n",
       "      <th>var_diff14</th>\n",
       "      <th>var_diff15</th>\n",
       "      <th>var_diff16</th>\n",
       "      <th>var_diff17</th>\n",
       "      <th>var_diff18</th>\n",
       "      <th>var_diff19</th>\n",
       "      <th>scenes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575796</td>\n",
       "      <td>0.717401</td>\n",
       "      <td>0.539698</td>\n",
       "      <td>-1.062370</td>\n",
       "      <td>0.191049</td>\n",
       "      <td>-1.723536</td>\n",
       "      <td>-1.194319</td>\n",
       "      <td>0.053656</td>\n",
       "      <td>-0.209370</td>\n",
       "      <td>-0.200844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.655437</td>\n",
       "      <td>-0.839057</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.830228</td>\n",
       "      <td>-0.783522</td>\n",
       "      <td>-0.736217</td>\n",
       "      <td>-0.683096</td>\n",
       "      <td>-0.866754</td>\n",
       "      <td>-0.571898</td>\n",
       "      <td>tubestation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.626746</td>\n",
       "      <td>1.382491</td>\n",
       "      <td>0.447212</td>\n",
       "      <td>-1.766357</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>2.536803</td>\n",
       "      <td>0.380988</td>\n",
       "      <td>1.120369</td>\n",
       "      <td>3.892846</td>\n",
       "      <td>4.094601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.906597</td>\n",
       "      <td>-0.561817</td>\n",
       "      <td>-0.990822</td>\n",
       "      <td>-0.910512</td>\n",
       "      <td>-0.770320</td>\n",
       "      <td>-1.019891</td>\n",
       "      <td>-1.231433</td>\n",
       "      <td>-0.857304</td>\n",
       "      <td>-0.888658</td>\n",
       "      <td>train-ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.484043</td>\n",
       "      <td>0.597128</td>\n",
       "      <td>1.028187</td>\n",
       "      <td>-1.412017</td>\n",
       "      <td>1.534679</td>\n",
       "      <td>0.511047</td>\n",
       "      <td>1.286969</td>\n",
       "      <td>0.967864</td>\n",
       "      <td>-0.259907</td>\n",
       "      <td>0.790211</td>\n",
       "      <td>...</td>\n",
       "      <td>1.939481</td>\n",
       "      <td>2.260830</td>\n",
       "      <td>2.335424</td>\n",
       "      <td>2.172651</td>\n",
       "      <td>2.198847</td>\n",
       "      <td>2.151799</td>\n",
       "      <td>1.910007</td>\n",
       "      <td>1.362777</td>\n",
       "      <td>1.451639</td>\n",
       "      <td>bus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean0     mean1     mean2     mean3     mean4     mean5     mean6  \\\n",
       "0  0.575796  0.717401  0.539698 -1.062370  0.191049 -1.723536 -1.194319   \n",
       "1 -0.626746  1.382491  0.447212 -1.766357  0.009479  2.536803  0.380988   \n",
       "2 -0.484043  0.597128  1.028187 -1.412017  1.534679  0.511047  1.286969   \n",
       "\n",
       "      mean7     mean8     mean9     ...       var_diff11  var_diff12  \\\n",
       "0  0.053656 -0.209370 -0.200844     ...        -0.655437   -0.839057   \n",
       "1  1.120369  3.892846  4.094601     ...        -0.906597   -0.561817   \n",
       "2  0.967864 -0.259907  0.790211     ...         1.939481    2.260830   \n",
       "\n",
       "   var_diff13  var_diff14  var_diff15  var_diff16  var_diff17  var_diff18  \\\n",
       "0   -0.300258   -0.830228   -0.783522   -0.736217   -0.683096   -0.866754   \n",
       "1   -0.990822   -0.910512   -0.770320   -1.019891   -1.231433   -0.857304   \n",
       "2    2.335424    2.172651    2.198847    2.151799    1.910007    1.362777   \n",
       "\n",
       "   var_diff19       scenes  \n",
       "0   -0.571898  tubestation  \n",
       "1   -0.888658    train-ter  \n",
       "2    1.451639          bus  \n",
       "\n",
       "[3 rows x 161 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrainCombined1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>mean5</th>\n",
       "      <th>mean6</th>\n",
       "      <th>mean7</th>\n",
       "      <th>mean8</th>\n",
       "      <th>mean9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575796</td>\n",
       "      <td>0.717401</td>\n",
       "      <td>0.539698</td>\n",
       "      <td>-1.062370</td>\n",
       "      <td>0.191049</td>\n",
       "      <td>-1.723536</td>\n",
       "      <td>-1.194319</td>\n",
       "      <td>0.053656</td>\n",
       "      <td>-0.209370</td>\n",
       "      <td>-0.200844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.626746</td>\n",
       "      <td>1.382491</td>\n",
       "      <td>0.447212</td>\n",
       "      <td>-1.766357</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>2.536803</td>\n",
       "      <td>0.380988</td>\n",
       "      <td>1.120369</td>\n",
       "      <td>3.892846</td>\n",
       "      <td>4.094601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.484043</td>\n",
       "      <td>0.597128</td>\n",
       "      <td>1.028187</td>\n",
       "      <td>-1.412017</td>\n",
       "      <td>1.534679</td>\n",
       "      <td>0.511047</td>\n",
       "      <td>1.286969</td>\n",
       "      <td>0.967864</td>\n",
       "      <td>-0.259907</td>\n",
       "      <td>0.790211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean0     mean1     mean2     mean3     mean4     mean5     mean6  \\\n",
       "0  0.575796  0.717401  0.539698 -1.062370  0.191049 -1.723536 -1.194319   \n",
       "1 -0.626746  1.382491  0.447212 -1.766357  0.009479  2.536803  0.380988   \n",
       "2 -0.484043  0.597128  1.028187 -1.412017  1.534679  0.511047  1.286969   \n",
       "\n",
       "      mean7     mean8     mean9  \n",
       "0  0.053656 -0.209370 -0.200844  \n",
       "1  1.120369  3.892846  4.094601  \n",
       "2  0.967864 -0.259907  0.790211  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain10feat1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data2 (Generalizability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Validation Data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading training data2\n",
    "dftrain_data2 = pd.read_csv('Data2/Data2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading validation data2\n",
    "dfvalid_data2 = pd.read_csv('Data2/Data2_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Concatenating the 2 sets to form ONE TRAINING SET\n",
    "dftrainCombined2 = pd.concat([dftrain_data2, dfvalid_data2], axis=0)\n",
    "\n",
    "# Subsetting training to take the first 10 features only\n",
    "dftrain10feat2 = dftrainCombined2.iloc[:,:10].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>mean5</th>\n",
       "      <th>mean6</th>\n",
       "      <th>mean7</th>\n",
       "      <th>mean8</th>\n",
       "      <th>mean9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_diff11</th>\n",
       "      <th>var_diff12</th>\n",
       "      <th>var_diff13</th>\n",
       "      <th>var_diff14</th>\n",
       "      <th>var_diff15</th>\n",
       "      <th>var_diff16</th>\n",
       "      <th>var_diff17</th>\n",
       "      <th>var_diff18</th>\n",
       "      <th>var_diff19</th>\n",
       "      <th>scenes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093323</td>\n",
       "      <td>-0.399723</td>\n",
       "      <td>0.783561</td>\n",
       "      <td>-2.520351</td>\n",
       "      <td>2.564316</td>\n",
       "      <td>-0.604616</td>\n",
       "      <td>1.020544</td>\n",
       "      <td>1.818084</td>\n",
       "      <td>-2.152912</td>\n",
       "      <td>1.866948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.980404</td>\n",
       "      <td>-0.94053</td>\n",
       "      <td>-1.060487</td>\n",
       "      <td>-0.915270</td>\n",
       "      <td>-0.933561</td>\n",
       "      <td>-1.192804</td>\n",
       "      <td>-1.120846</td>\n",
       "      <td>-1.367337</td>\n",
       "      <td>-1.184519</td>\n",
       "      <td>train-ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076053</td>\n",
       "      <td>1.165681</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>-1.856342</td>\n",
       "      <td>0.366469</td>\n",
       "      <td>1.074824</td>\n",
       "      <td>0.338721</td>\n",
       "      <td>1.890659</td>\n",
       "      <td>3.694118</td>\n",
       "      <td>2.813581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.824649</td>\n",
       "      <td>-0.92521</td>\n",
       "      <td>-0.656642</td>\n",
       "      <td>-0.723337</td>\n",
       "      <td>-0.911938</td>\n",
       "      <td>-0.838659</td>\n",
       "      <td>-0.662626</td>\n",
       "      <td>-0.954069</td>\n",
       "      <td>-0.782338</td>\n",
       "      <td>train-ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.855206</td>\n",
       "      <td>1.212459</td>\n",
       "      <td>-0.488913</td>\n",
       "      <td>0.914367</td>\n",
       "      <td>-0.056152</td>\n",
       "      <td>-0.089688</td>\n",
       "      <td>1.160520</td>\n",
       "      <td>0.783487</td>\n",
       "      <td>0.425175</td>\n",
       "      <td>-0.174028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.758511</td>\n",
       "      <td>-0.88437</td>\n",
       "      <td>-1.231002</td>\n",
       "      <td>-0.600003</td>\n",
       "      <td>-0.559877</td>\n",
       "      <td>-0.837631</td>\n",
       "      <td>-0.818048</td>\n",
       "      <td>-0.670121</td>\n",
       "      <td>-0.492715</td>\n",
       "      <td>busystreet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean0     mean1     mean2     mean3     mean4     mean5     mean6  \\\n",
       "0  0.093323 -0.399723  0.783561 -2.520351  2.564316 -0.604616  1.020544   \n",
       "1  0.076053  1.165681  0.960745 -1.856342  0.366469  1.074824  0.338721   \n",
       "2  0.855206  1.212459 -0.488913  0.914367 -0.056152 -0.089688  1.160520   \n",
       "\n",
       "      mean7     mean8     mean9     ...      var_diff11  var_diff12  \\\n",
       "0  1.818084 -2.152912  1.866948     ...       -0.980404    -0.94053   \n",
       "1  1.890659  3.694118  2.813581     ...       -0.824649    -0.92521   \n",
       "2  0.783487  0.425175 -0.174028     ...       -0.758511    -0.88437   \n",
       "\n",
       "   var_diff13  var_diff14  var_diff15  var_diff16  var_diff17  var_diff18  \\\n",
       "0   -1.060487   -0.915270   -0.933561   -1.192804   -1.120846   -1.367337   \n",
       "1   -0.656642   -0.723337   -0.911938   -0.838659   -0.662626   -0.954069   \n",
       "2   -1.231002   -0.600003   -0.559877   -0.837631   -0.818048   -0.670121   \n",
       "\n",
       "   var_diff19      scenes  \n",
       "0   -1.184519   train-ter  \n",
       "1   -0.782338   train-ter  \n",
       "2   -0.492715  busystreet  \n",
       "\n",
       "[3 rows x 161 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrainCombined2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>mean5</th>\n",
       "      <th>mean6</th>\n",
       "      <th>mean7</th>\n",
       "      <th>mean8</th>\n",
       "      <th>mean9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093323</td>\n",
       "      <td>-0.399723</td>\n",
       "      <td>0.783561</td>\n",
       "      <td>-2.520351</td>\n",
       "      <td>2.564316</td>\n",
       "      <td>-0.604616</td>\n",
       "      <td>1.020544</td>\n",
       "      <td>1.818084</td>\n",
       "      <td>-2.152912</td>\n",
       "      <td>1.866948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076053</td>\n",
       "      <td>1.165681</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>-1.856342</td>\n",
       "      <td>0.366469</td>\n",
       "      <td>1.074824</td>\n",
       "      <td>0.338721</td>\n",
       "      <td>1.890659</td>\n",
       "      <td>3.694118</td>\n",
       "      <td>2.813581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.855206</td>\n",
       "      <td>1.212459</td>\n",
       "      <td>-0.488913</td>\n",
       "      <td>0.914367</td>\n",
       "      <td>-0.056152</td>\n",
       "      <td>-0.089688</td>\n",
       "      <td>1.160520</td>\n",
       "      <td>0.783487</td>\n",
       "      <td>0.425175</td>\n",
       "      <td>-0.174028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean0     mean1     mean2     mean3     mean4     mean5     mean6  \\\n",
       "0  0.093323 -0.399723  0.783561 -2.520351  2.564316 -0.604616  1.020544   \n",
       "1  0.076053  1.165681  0.960745 -1.856342  0.366469  1.074824  0.338721   \n",
       "2  0.855206  1.212459 -0.488913  0.914367 -0.056152 -0.089688  1.160520   \n",
       "\n",
       "      mean7     mean8     mean9  \n",
       "0  1.818084 -2.152912  1.866948  \n",
       "1  1.890659  3.694118  2.813581  \n",
       "2  0.783487  0.425175 -0.174028  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain10feat2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tubestation', 'train-ter', 'bus', 'market', 'restaurant',\n",
       "       'busystreet', 'quietstreet'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrainCombined1.scenes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups (Zero-indexed, 6 groups in total)\n",
    "0 - tubestation, 1 - quietstreet, 2 - busystreet, 3 - restaurant, 4 - market\n",
    "\n",
    "#### scene values that were set to the \"general\" group, number 5\n",
    "general group = bus, train-ter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dictionary of tuples (the keys require the \",\" after the string so python sees it as tuple) \n",
    "# for each scene and group the general scenes into one. Zero-indexed for NN function\n",
    "scene_list = {(\"tubestation\",): 0, (\"quietstreet\",): 1, (\"busystreet\",): 2, (\"restaurant\",): 3, \n",
    "             (\"market\",): 4, (\"bus\", \"train-ter\",): 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create function to loop through and assign the number values to each scene type\n",
    "# since column 'scene_type' doesn't exist, initialize with zeros then check uniques\n",
    "\n",
    "def createLabels(label_list, dataset):\n",
    "    dataset['scene_type'] = np.zeros(len(dataset), dtype=np.int)\n",
    "    \n",
    "    for key, value in label_list.iteritems():\n",
    "        dataset['scene_type'][dataset['scenes'].isin(key)] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenes</th>\n",
       "      <th>scene_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tubestation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-ter</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>market</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train-ter</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tubestation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train-ter</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>busystreet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        scenes  scene_type\n",
       "0  tubestation           0\n",
       "1    train-ter           5\n",
       "2          bus           5\n",
       "3       market           4\n",
       "4    train-ter           5\n",
       "5  tubestation           0\n",
       "6    train-ter           5\n",
       "7          bus           5\n",
       "8   restaurant           3\n",
       "9   busystreet           2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createLabels(scene_list, dftrainCombined1)\n",
    "dftrainCombined1[[\"scenes\",\"scene_type\"]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenes</th>\n",
       "      <th>scene_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train-ter</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-ter</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>busystreet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>market</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>busystreet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>market</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train-ter</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>market</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       scenes  scene_type\n",
       "0   train-ter           5\n",
       "1   train-ter           5\n",
       "2  busystreet           2\n",
       "3  restaurant           3\n",
       "4      market           4\n",
       "5  busystreet           2\n",
       "6      market           4\n",
       "7   train-ter           5\n",
       "8      market           4\n",
       "9  restaurant           3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createLabels(scene_list, dftrainCombined2)\n",
    "dftrainCombined2[[\"scenes\",\"scene_type\"]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenes</th>\n",
       "      <th>scene_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenes  scene_type\n",
       "0    bus           5\n",
       "1    bus           5\n",
       "2    bus           5\n",
       "3    bus           5\n",
       "4    bus           5\n",
       "5    bus           5\n",
       "6    bus           5\n",
       "7    bus           5\n",
       "8    bus           5\n",
       "9    bus           5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createLabels(scene_list, dftest_data1)\n",
    "dftest_data1[[\"scenes\",\"scene_type\"]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenes</th>\n",
       "      <th>scene_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>busystreet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-ter</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>busystreet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quietstreet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>market</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tubestation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        scenes  scene_type\n",
       "0          bus           5\n",
       "1   busystreet           2\n",
       "2    train-ter           5\n",
       "3   busystreet           2\n",
       "4  quietstreet           1\n",
       "5   restaurant           3\n",
       "6         tube           0\n",
       "7       market           4\n",
       "8  tubestation           0\n",
       "9          bus           5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createLabels(scene_list, dftest_data2)\n",
    "dftest_data2[[\"scenes\",\"scene_type\"]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    5\n",
       "2    5\n",
       "Name: scene_type, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_labels1 = dftrainCombined1.scene_type.copy()\n",
    "ytrain_labels1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "2    2\n",
       "Name: scene_type, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_labels2 = dftrainCombined2.scene_type.copy()\n",
    "ytrain_labels2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " **** For 70/30 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n",
      "... training the model\n",
      "epoch 500, minibatch 4/4, validation error 10.125000 %\n",
      "epoch 500, minibatch 4/4, test error of best model 22.250000 %\n",
      "epoch 1000, minibatch 4/4, validation error 10.125000 %\n",
      "epoch 1500, minibatch 4/4, validation error 9.125000 %\n",
      "epoch 1500, minibatch 4/4, test error of best model 23.500000 %\n",
      "epoch 2000, minibatch 4/4, validation error 8.875000 %\n",
      "epoch 2000, minibatch 4/4, test error of best model 22.250000 %\n",
      "epoch 2500, minibatch 4/4, validation error 9.250000 %\n",
      "epoch 3000, minibatch 4/4, validation error 9.000000 %\n",
      "epoch 3500, minibatch 4/4, validation error 8.625000 %\n",
      "epoch 3500, minibatch 4/4, test error of best model 21.500000 %\n",
      "epoch 4000, minibatch 4/4, validation error 8.250000 %\n",
      "epoch 4000, minibatch 4/4, test error of best model 20.750000 %\n",
      "epoch 4500, minibatch 4/4, validation error 8.375000 %\n",
      "epoch 5000, minibatch 4/4, validation error 8.250000 %\n",
      "epoch 5500, minibatch 4/4, validation error 8.000000 %\n",
      "epoch 5500, minibatch 4/4, test error of best model 22.000000 %\n",
      "epoch 6000, minibatch 4/4, validation error 7.625000 %\n",
      "epoch 6000, minibatch 4/4, test error of best model 22.000000 %\n",
      "epoch 6500, minibatch 4/4, validation error 7.875000 %\n",
      "epoch 7000, minibatch 4/4, validation error 7.875000 %\n",
      "Optimization complete with best validation score of 7.625000 %,with test performance 22.000000 %\n",
      "The code ran for 7000 epochs, with 1315.856953 epochs/sec\n",
      "\n",
      "\n",
      " **** For 72/28 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 5.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training the model\n",
      "epoch 400, minibatch 5/5, validation error 11.200000 %\n",
      "epoch 400, minibatch 5/5, test error of best model 23.500000 %\n",
      "epoch 800, minibatch 5/5, validation error 11.600000 %\n",
      "epoch 1200, minibatch 5/5, validation error 11.500000 %\n",
      "Optimization complete with best validation score of 11.200000 %,with test performance 23.500000 %\n",
      "The code ran for 1600 epochs, with 1084.428038 epochs/sec\n",
      "\n",
      "\n",
      " **** For 74/26 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training the model\n",
      "epoch 400, minibatch 5/5, validation error 11.600000 %\n",
      "epoch 400, minibatch 5/5, test error of best model 24.500000 %\n",
      "epoch 800, minibatch 5/5, validation error 10.200000 %\n",
      "epoch 800, minibatch 5/5, test error of best model 24.000000 %\n",
      "epoch 1200, minibatch 5/5, validation error 10.300000 %\n",
      "epoch 1600, minibatch 5/5, validation error 10.400000 %\n",
      "epoch 2000, minibatch 5/5, validation error 10.900000 %\n",
      "epoch 2400, minibatch 5/5, validation error 11.400000 %\n",
      "epoch 2800, minibatch 5/5, validation error 11.100000 %\n",
      "Optimization complete with best validation score of 10.200000 %,with test performance 24.000000 %\n",
      "The code ran for 3200 epochs, with 1048.156983 epochs/sec\n",
      "\n",
      "\n",
      " **** For 76/24 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training the model\n",
      "epoch 400, minibatch 5/5, validation error 10.000000 %\n",
      "epoch 400, minibatch 5/5, test error of best model 23.000000 %\n",
      "epoch 800, minibatch 5/5, validation error 9.400000 %\n",
      "epoch 800, minibatch 5/5, test error of best model 24.000000 %\n",
      "epoch 1200, minibatch 5/5, validation error 9.000000 %\n",
      "epoch 1200, minibatch 5/5, test error of best model 23.000000 %\n",
      "epoch 1600, minibatch 5/5, validation error 8.600000 %\n",
      "epoch 1600, minibatch 5/5, test error of best model 21.000000 %\n",
      "epoch 2000, minibatch 5/5, validation error 8.800000 %\n",
      "epoch 2400, minibatch 5/5, validation error 8.700000 %\n",
      "epoch 2800, minibatch 5/5, validation error 9.000000 %\n",
      "epoch 3200, minibatch 5/5, validation error 9.000000 %\n",
      "epoch 3600, minibatch 5/5, validation error 9.000000 %\n",
      "epoch 4000, minibatch 5/5, validation error 8.800000 %\n",
      "epoch 4400, minibatch 5/5, validation error 8.800000 %\n",
      "epoch 4800, minibatch 5/5, validation error 8.500000 %\n",
      "epoch 4800, minibatch 5/5, test error of best model 22.000000 %\n",
      "epoch 5200, minibatch 5/5, validation error 8.700000 %\n",
      "epoch 5600, minibatch 5/5, validation error 8.800000 %\n",
      "epoch 6000, minibatch 5/5, validation error 8.900000 %\n",
      "epoch 6400, minibatch 5/5, validation error 8.900000 %\n",
      "epoch 6800, minibatch 5/5, validation error 8.900000 %\n",
      "Optimization complete with best validation score of 8.500000 %,with test performance 22.000000 %\n",
      "The code ran for 7000 epochs, with 1038.852930 epochs/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 6.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " **** For 78/22 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n",
      "... training the model\n",
      "epoch 400, minibatch 5/5, validation error 10.400000 %\n",
      "epoch 400, minibatch 5/5, test error of best model 25.000000 %\n",
      "epoch 800, minibatch 5/5, validation error 9.200000 %\n",
      "epoch 800, minibatch 5/5, test error of best model 22.000000 %\n",
      "epoch 1200, minibatch 5/5, validation error 9.400000 %\n",
      "epoch 1600, minibatch 5/5, validation error 9.100000 %\n",
      "epoch 1600, minibatch 5/5, test error of best model 21.500000 %\n",
      "epoch 2000, minibatch 5/5, validation error 8.900000 %\n",
      "epoch 2000, minibatch 5/5, test error of best model 22.500000 %\n",
      "epoch 2400, minibatch 5/5, validation error 8.700000 %\n",
      "epoch 2400, minibatch 5/5, test error of best model 22.000000 %\n",
      "epoch 2800, minibatch 5/5, validation error 8.800000 %\n",
      "epoch 3200, minibatch 5/5, validation error 8.800000 %\n",
      "epoch 3600, minibatch 5/5, validation error 8.400000 %\n",
      "epoch 3600, minibatch 5/5, test error of best model 22.000000 %\n",
      "epoch 4000, minibatch 5/5, validation error 8.400000 %\n",
      "epoch 4400, minibatch 5/5, validation error 8.300000 %\n",
      "epoch 4400, minibatch 5/5, test error of best model 21.500000 %\n",
      "epoch 4800, minibatch 5/5, validation error 8.300000 %\n",
      "epoch 5200, minibatch 5/5, validation error 8.300000 %\n",
      "epoch 5600, minibatch 5/5, validation error 8.300000 %\n",
      "epoch 6000, minibatch 5/5, validation error 8.500000 %\n",
      "epoch 6400, minibatch 5/5, validation error 8.300000 %\n",
      "epoch 6800, minibatch 5/5, validation error 8.500000 %\n",
      "Optimization complete with best validation score of 8.300000 %,with test performance 21.500000 %\n",
      "The code ran for 7000 epochs, with 1049.156596 epochs/sec\n",
      "\n",
      "\n",
      " **** For 80/20 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 6.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training the model\n",
      "epoch 400, minibatch 5/5, validation error 11.600000 %\n",
      "epoch 400, minibatch 5/5, test error of best model 24.500000 %\n",
      "epoch 800, minibatch 5/5, validation error 11.400000 %\n",
      "epoch 800, minibatch 5/5, test error of best model 21.000000 %\n",
      "epoch 1200, minibatch 5/5, validation error 10.500000 %\n",
      "epoch 1200, minibatch 5/5, test error of best model 20.500000 %\n",
      "epoch 1600, minibatch 5/5, validation error 10.300000 %\n",
      "epoch 1600, minibatch 5/5, test error of best model 20.500000 %\n",
      "epoch 2000, minibatch 5/5, validation error 10.200000 %\n",
      "epoch 2000, minibatch 5/5, test error of best model 22.000000 %\n",
      "epoch 2400, minibatch 5/5, validation error 10.300000 %\n",
      "epoch 2800, minibatch 5/5, validation error 9.700000 %\n",
      "epoch 2800, minibatch 5/5, test error of best model 23.000000 %\n",
      "epoch 3200, minibatch 5/5, validation error 9.900000 %\n",
      "epoch 3600, minibatch 5/5, validation error 9.900000 %\n",
      "epoch 4000, minibatch 5/5, validation error 9.900000 %\n",
      "epoch 4400, minibatch 5/5, validation error 10.300000 %\n",
      "epoch 4800, minibatch 5/5, validation error 10.100000 %\n",
      "epoch 5200, minibatch 5/5, validation error 10.200000 %\n",
      "epoch 5600, minibatch 5/5, validation error 9.800000 %\n",
      "epoch 6000, minibatch 5/5, validation error 9.700000 %\n",
      "epoch 6400, minibatch 5/5, validation error 9.900000 %\n",
      "epoch 6800, minibatch 5/5, validation error 9.600000 %\n",
      "epoch 6800, minibatch 5/5, test error of best model 22.000000 %\n",
      "Optimization complete with best validation score of 9.600000 %,with test performance 22.000000 %\n",
      "The code ran for 7000 epochs, with 1058.548128 epochs/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 6.6s\n"
     ]
    }
   ],
   "source": [
    "validationSize = [0.30, 0.28, 0.26, 0.24, 0.22, 0.20]\n",
    "\n",
    "for i in validationSize:\n",
    "    \n",
    "    # splitting the dataset\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(dftrain10feat1, ytrain_labels1, test_size=i, random_state=39)\n",
    "    \n",
    "    # Printing reference header\n",
    "    testing = 100 * i\n",
    "    training = 100 - testing\n",
    "    print '\\n\\n **** For %d/%d data split ratio **** : \\n' %(training, testing)\n",
    "    \n",
    "    nc = neural_classifier()\n",
    "    nc.train(learning_rate=0.85, n_epochs=7000,\n",
    "    X_train=X_train, Y_train=Y_train, X_test=X_test, Y_test=Y_test, batch_size=200, \n",
    "    print_frequency=2000, n_in=10, n_out=6, n_hidden=7, n_layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b> \n",
    "- Validation Error Average : 9.2375\n",
    "- Test Error Average       : 22.5\n",
    "- Best split 70/30         : 7.625/22 (Validation/Test)\n",
    "<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " **** For 70/30 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n",
      "... training the model\n",
      "epoch 667, minibatch 2/3, validation error 10.000000 %\n",
      "epoch 667, minibatch 2/3, test error of best model 17.500000 %\n",
      "epoch 1334, minibatch 1/3, validation error 7.666667 %\n",
      "epoch 1334, minibatch 1/3, test error of best model 20.500000 %\n",
      "epoch 2000, minibatch 3/3, validation error 6.666667 %\n",
      "epoch 2000, minibatch 3/3, test error of best model 19.000000 %\n",
      "epoch 2667, minibatch 2/3, validation error 5.833333 %\n",
      "epoch 2667, minibatch 2/3, test error of best model 20.000000 %\n",
      "epoch 3334, minibatch 1/3, validation error 5.000000 %\n",
      "epoch 3334, minibatch 1/3, test error of best model 20.000000 %\n",
      "epoch 4000, minibatch 3/3, validation error 4.666667 %\n",
      "epoch 4000, minibatch 3/3, test error of best model 21.000000 %\n",
      "epoch 4667, minibatch 2/3, validation error 4.666667 %\n",
      "epoch 5334, minibatch 1/3, validation error 4.166667 %\n",
      "epoch 5334, minibatch 1/3, test error of best model 22.000000 %\n",
      "epoch 6000, minibatch 3/3, validation error 4.333333 %\n",
      "epoch 6667, minibatch 2/3, validation error 4.000000 %\n",
      "epoch 6667, minibatch 2/3, test error of best model 22.000000 %\n",
      "Optimization complete with best validation score of 4.000000 %,with test performance 22.000000 %\n",
      "The code ran for 7000 epochs, with 1623.413502 epochs/sec\n",
      "\n",
      "\n",
      " **** For 72/28 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training the model\n",
      "epoch 667, minibatch 2/3, validation error 11.000000 %\n",
      "epoch 667, minibatch 2/3, test error of best model 18.000000 %\n",
      "epoch 1334, minibatch 1/3, validation error 7.833333 %\n",
      "epoch 1334, minibatch 1/3, test error of best model 20.000000 %\n",
      "epoch 2000, minibatch 3/3, validation error 6.666667 %\n",
      "epoch 2000, minibatch 3/3, test error of best model 19.000000 %\n",
      "epoch 2667, minibatch 2/3, validation error 7.333333 %\n",
      "epoch 3334, minibatch 1/3, validation error 7.166667 %\n",
      "epoch 4000, minibatch 3/3, validation error 6.500000 %\n",
      "epoch 4000, minibatch 3/3, test error of best model 20.500000 %\n",
      "epoch 4667, minibatch 2/3, validation error 5.666667 %\n",
      "epoch 4667, minibatch 2/3, test error of best model 20.500000 %\n",
      "epoch 5334, minibatch 1/3, validation error 5.166667 %\n",
      "epoch 5334, minibatch 1/3, test error of best model 20.500000 %\n",
      "epoch 6000, minibatch 3/3, validation error 4.666667 %\n",
      "epoch 6000, minibatch 3/3, test error of best model 20.500000 %\n",
      "epoch 6667, minibatch 2/3, validation error 4.000000 %\n",
      "epoch 6667, minibatch 2/3, test error of best model 20.000000 %\n",
      "Optimization complete with best validation score of 4.000000 %,with test performance 20.000000 %\n",
      "The code ran for 7000 epochs, with 1525.111295 epochs/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 4.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " **** For 74/26 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n",
      "... training the model\n",
      "epoch 667, minibatch 2/3, validation error 9.000000 %\n",
      "epoch 667, minibatch 2/3, test error of best model 20.000000 %\n",
      "epoch 1334, minibatch 1/3, validation error 7.166667 %\n",
      "epoch 1334, minibatch 1/3, test error of best model 22.500000 %\n",
      "epoch 2000, minibatch 3/3, validation error 6.000000 %\n",
      "epoch 2000, minibatch 3/3, test error of best model 21.000000 %\n",
      "epoch 2667, minibatch 2/3, validation error 5.333333 %\n",
      "epoch 2667, minibatch 2/3, test error of best model 22.000000 %\n",
      "epoch 3334, minibatch 1/3, validation error 5.500000 %\n",
      "epoch 4000, minibatch 3/3, validation error 5.666667 %\n",
      "epoch 4667, minibatch 2/3, validation error 5.333333 %\n",
      "epoch 5334, minibatch 1/3, validation error 5.000000 %\n",
      "epoch 5334, minibatch 1/3, test error of best model 23.500000 %\n",
      "epoch 6000, minibatch 3/3, validation error 5.166667 %\n",
      "epoch 6667, minibatch 2/3, validation error 5.000000 %\n",
      "Optimization complete with best validation score of 5.000000 %,with test performance 23.500000 %\n",
      "The code ran for 7000 epochs, with 1595.471056 epochs/sec\n",
      "\n",
      "\n",
      " **** For 76/24 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training the model\n",
      "epoch 500, minibatch 4/4, validation error 12.875000 %\n",
      "epoch 500, minibatch 4/4, test error of best model 21.000000 %\n",
      "epoch 1000, minibatch 4/4, validation error 11.125000 %\n",
      "epoch 1000, minibatch 4/4, test error of best model 21.000000 %\n",
      "epoch 1500, minibatch 4/4, validation error 10.250000 %\n",
      "epoch 1500, minibatch 4/4, test error of best model 21.000000 %\n",
      "epoch 2000, minibatch 4/4, validation error 10.500000 %\n",
      "epoch 2500, minibatch 4/4, validation error 9.500000 %\n",
      "epoch 2500, minibatch 4/4, test error of best model 20.000000 %\n",
      "epoch 3000, minibatch 4/4, validation error 9.875000 %\n",
      "epoch 3500, minibatch 4/4, validation error 10.000000 %\n",
      "epoch 4000, minibatch 4/4, validation error 9.625000 %\n",
      "epoch 4500, minibatch 4/4, validation error 9.375000 %\n",
      "epoch 4500, minibatch 4/4, test error of best model 25.000000 %\n",
      "epoch 5000, minibatch 4/4, validation error 9.250000 %\n",
      "epoch 5000, minibatch 4/4, test error of best model 25.000000 %\n",
      "epoch 5500, minibatch 4/4, validation error 9.125000 %\n",
      "epoch 5500, minibatch 4/4, test error of best model 26.500000 %\n",
      "epoch 6000, minibatch 4/4, validation error 9.000000 %\n",
      "epoch 6000, minibatch 4/4, test error of best model 26.000000 %\n",
      "epoch 6500, minibatch 4/4, validation error 9.000000 %\n",
      "epoch 7000, minibatch 4/4, validation error 8.875000 %\n",
      "epoch 7000, minibatch 4/4, test error of best model 26.000000 %\n",
      "Optimization complete with best validation score of 8.875000 %,with test performance 26.000000 %\n",
      "The code ran for 7000 epochs, with 1215.153092 epochs/sec\n",
      "\n",
      "\n",
      " **** For 78/22 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 5.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training the model\n",
      "epoch 500, minibatch 4/4, validation error 11.125000 %\n",
      "epoch 500, minibatch 4/4, test error of best model 19.500000 %\n",
      "epoch 1000, minibatch 4/4, validation error 10.250000 %\n",
      "epoch 1000, minibatch 4/4, test error of best model 21.000000 %\n",
      "epoch 1500, minibatch 4/4, validation error 10.250000 %\n",
      "epoch 1500, minibatch 4/4, test error of best model 20.000000 %\n",
      "epoch 2000, minibatch 4/4, validation error 9.875000 %\n",
      "epoch 2000, minibatch 4/4, test error of best model 21.000000 %\n",
      "epoch 2500, minibatch 4/4, validation error 9.125000 %\n",
      "epoch 2500, minibatch 4/4, test error of best model 23.000000 %\n",
      "epoch 3000, minibatch 4/4, validation error 8.500000 %\n",
      "epoch 3000, minibatch 4/4, test error of best model 23.000000 %\n",
      "epoch 3500, minibatch 4/4, validation error 8.375000 %\n",
      "epoch 3500, minibatch 4/4, test error of best model 24.500000 %\n",
      "epoch 4000, minibatch 4/4, validation error 8.125000 %\n",
      "epoch 4000, minibatch 4/4, test error of best model 24.500000 %\n",
      "epoch 4500, minibatch 4/4, validation error 8.125000 %\n",
      "epoch 5000, minibatch 4/4, validation error 7.625000 %\n",
      "epoch 5000, minibatch 4/4, test error of best model 25.500000 %\n",
      "epoch 5500, minibatch 4/4, validation error 7.250000 %\n",
      "epoch 5500, minibatch 4/4, test error of best model 25.000000 %\n",
      "epoch 6000, minibatch 4/4, validation error 7.250000 %\n",
      "epoch 6500, minibatch 4/4, validation error 6.500000 %\n",
      "epoch 6500, minibatch 4/4, test error of best model 24.000000 %\n",
      "epoch 7000, minibatch 4/4, validation error 6.250000 %\n",
      "epoch 7000, minibatch 4/4, test error of best model 24.000000 %\n",
      "Optimization complete with best validation score of 6.250000 %,with test performance 24.000000 %\n",
      "The code ran for 7000 epochs, with 1191.024485 epochs/sec\n",
      "\n",
      "\n",
      " **** For 80/20 data split ratio **** : \n",
      "\n",
      "using training set as validation set...\n",
      "... building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 5.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training the model\n",
      "epoch 500, minibatch 4/4, validation error 11.500000 %\n",
      "epoch 500, minibatch 4/4, test error of best model 16.000000 %\n",
      "epoch 1000, minibatch 4/4, validation error 9.875000 %\n",
      "epoch 1000, minibatch 4/4, test error of best model 16.500000 %\n",
      "epoch 1500, minibatch 4/4, validation error 9.625000 %\n",
      "epoch 1500, minibatch 4/4, test error of best model 17.000000 %\n",
      "epoch 2000, minibatch 4/4, validation error 9.375000 %\n",
      "epoch 2000, minibatch 4/4, test error of best model 17.000000 %\n",
      "epoch 2500, minibatch 4/4, validation error 9.125000 %\n",
      "epoch 2500, minibatch 4/4, test error of best model 19.000000 %\n",
      "epoch 3000, minibatch 4/4, validation error 9.250000 %\n",
      "epoch 3500, minibatch 4/4, validation error 8.750000 %\n",
      "epoch 3500, minibatch 4/4, test error of best model 20.500000 %\n",
      "epoch 4000, minibatch 4/4, validation error 8.750000 %\n",
      "epoch 4500, minibatch 4/4, validation error 8.500000 %\n",
      "epoch 4500, minibatch 4/4, test error of best model 20.500000 %\n",
      "epoch 5000, minibatch 4/4, validation error 8.375000 %\n",
      "epoch 5000, minibatch 4/4, test error of best model 21.000000 %\n",
      "epoch 5500, minibatch 4/4, validation error 7.750000 %\n",
      "epoch 5500, minibatch 4/4, test error of best model 21.000000 %\n",
      "epoch 6000, minibatch 4/4, validation error 8.000000 %\n",
      "epoch 6500, minibatch 4/4, validation error 8.625000 %\n",
      "epoch 7000, minibatch 4/4, validation error 8.250000 %\n",
      "Optimization complete with best validation score of 7.750000 %,with test performance 21.000000 %\n",
      "The code ran for 7000 epochs, with 1207.813035 epochs/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file neural_classifier.pyc ran for 5.8s\n"
     ]
    }
   ],
   "source": [
    "validationSize = [0.30, 0.28, 0.26, 0.24, 0.22, 0.20]\n",
    "\n",
    "for i in validationSize:\n",
    "    \n",
    "    # splitting the dataset\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(dftrain10feat2, ytrain_labels2, test_size=i, random_state=39)\n",
    "    \n",
    "    # Printing reference header\n",
    "    testing = 100 * i\n",
    "    training = 100 - testing\n",
    "    print '\\n\\n **** For %d/%d data split ratio **** : \\n' %(training, testing)\n",
    "    \n",
    "    nc = neural_classifier()\n",
    "    nc.train(learning_rate=0.45, n_epochs=7000,\n",
    "    X_train=X_train, Y_train=Y_train, X_test=X_test, Y_test=Y_test, batch_size=200, \n",
    "    print_frequency=2000, n_in=10, n_out=6, n_hidden=10, n_layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> \n",
    "- Validation Error Average : 5.97\n",
    "- Test Error Average       : 22.75\n",
    "- Best split 70/30         : 4/20 (Validation/Test)\n",
    "<b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
